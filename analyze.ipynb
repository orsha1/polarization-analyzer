{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from ase import Atoms\n",
    "from ase.io.vasp import read_vasp, write_vasp\n",
    "from ase.io.espresso import read_espresso_in, read_espresso_out\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import pprint\n",
    "from ase.units import create_units\n",
    "units = create_units('2006')\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"type\": \"vasp\",\n",
    "    \"name\": \"structure\",\n",
    "    \"path\": \"structure.vasp\",\n",
    "    \"save_pbc_vasp\": False,\n",
    "    \"read_all_steps\": False\n",
    "}\n",
    "\n",
    "with open(\"./config.json\", \"r\") as file:\n",
    "    config_load = json.load(file)\n",
    "\n",
    "config = {key: config_load.get(key, value) for key, value in config.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./born_effective_charges.json\", \"r\") as file:\n",
    "    zstars = json.load(file)\n",
    "\n",
    "b_sites = list(zstars[\"B-site\"].keys())\n",
    "a_sites = list(zstars[\"A-site\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbc(positions, cell, nat):\n",
    "    n = 3 * 3 * 3\n",
    "\n",
    "    positions_pbc = np.empty(shape=(nat * n, 7))\n",
    "    \n",
    "    k = 0\n",
    "    for i_x in range(-1, 2):\n",
    "        for i_y in range(-1, 2):\n",
    "            for i_z in range(-1, 2):\n",
    "                lp = cell.copy()\n",
    "                lp *= np.array([i_x, i_y, i_z])[:, np.newaxis] \n",
    "                disp_vec = lp.sum(axis=0)\n",
    "                positions_pbc[nat * k : nat * (k + 1), 1:4] = i_x, i_y, i_z\n",
    "                positions_pbc[nat * k : nat * (k + 1), 4:] = positions + disp_vec\n",
    "                k += 1\n",
    "\n",
    "    positions_pbc[:, 0] = np.tile(np.arange(nat), 27)\n",
    "\n",
    "    cell_pbc = cell * [3, 3, 3]\n",
    "    return (positions_pbc, cell_pbc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(point1, point2, point3):\n",
    "    vector1 = point1 - point2\n",
    "    vector2 = point3 - point2\n",
    "\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "\n",
    "    cos_theta = dot_product / (norm_vector1 * norm_vector2)\n",
    "    angle_rad = np.arccos(cos_theta)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    if angle_deg > 180:\n",
    "        angle_deg = 360 - angle_deg\n",
    "\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polarization(Z_star, displacements, volume):\n",
    "    e = 1.602176634e-19  # elementary charge in C\n",
    "\n",
    "    # Convert Ångström to meters\n",
    "    displacements_meters = displacements * 1.0e-10\n",
    "    # Convert Ångström³ to meters³\n",
    "    volume_meters3 = volume * 1.0e-30\n",
    "\n",
    "    polarization_x = e / volume_meters3 * Z_star * displacements_meters[0]\n",
    "    polarization_y = e / volume_meters3 * Z_star * displacements_meters[1]\n",
    "    polarization_z = e / volume_meters3 * Z_star * displacements_meters[2]\n",
    "\n",
    "    return np.array([polarization_x, polarization_y, polarization_z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Structure:\n",
    "    def __init__(self, obj, config):\n",
    "        self.obj = obj\n",
    "        self.coords_cartes = obj.get_positions()\n",
    "        self.coords_direct = obj.get_scaled_positions()\n",
    "        self.nat = obj.get_global_number_of_atoms()\n",
    "        self.symbols = obj.get_chemical_symbols()\n",
    "        self.cell = np.array(obj.get_cell())\n",
    "        self.V = obj.get_volume()\n",
    "        self.config = config\n",
    "        self.config['outname'] = config[\"name\"]+\".out\"\n",
    "\n",
    "    def get_pbc(self):\n",
    "        self.pbc_positions, self.cell_pbc = pbc(self.coords_cartes, self.cell, self.nat)\n",
    "        self.coords_cartes_pbc = self.pbc_positions[:, 4:]\n",
    "        self.symbols_pbc = np.tile(np.array(self.obj.symbols), 27)\n",
    "        self.obj_pbc = Atoms(positions = self.coords_cartes_pbc, cell = self.cell_pbc, symbols = self.symbols_pbc)\n",
    "\n",
    "    def get_disp_pol_alpha(self):\n",
    "        bool_o = self.symbols_pbc == \"O\"\n",
    "        bool_cat = self.symbols_pbc != \"O\"\n",
    "        bool_origin = (self.pbc_positions[:,1] == 0) & (self.pbc_positions[:,2] == 0) & (self.pbc_positions[:,3] == 0)\n",
    "\n",
    "        oxygens = self.coords_cartes_pbc[bool_o]\n",
    "        cations = self.coords_cartes_pbc[bool_origin & bool_cat]\n",
    "        cations_symbols = self.symbols_pbc[bool_origin & bool_cat]\n",
    "\n",
    "        dists = cdist(cations, oxygens)\n",
    "        V = self.V\n",
    "\n",
    "        disp_pol_alpha = {}\n",
    "        P = np.empty(shape = (len(cations), 3))\n",
    "        D = np.empty(shape = (len(cations), 3))\n",
    "        alphas = []\n",
    "\n",
    "        for i in range(len(cations)):\n",
    "            symbol = cations_symbols[i]\n",
    "            cation_coords = cations[i]\n",
    "            if symbol in a_sites:\n",
    "                #A = True\n",
    "                zstar = zstars[\"A-site\"][symbol]\n",
    "                hedra_idx = np.argpartition(dists[i], 12)[:12]\n",
    "                headra_coords = oxygens[hedra_idx]\n",
    "                center = headra_coords.mean(axis = 0)\n",
    "                d = cation_coords - center\n",
    "                p = calculate_polarization(zstar, d, V)\n",
    "                disp_pol_alpha[(\"A\", symbol, i)] = {\"p\":p, \"d\":d,\"hedra_idx\":hedra_idx, \"hedra\":headra_coords, \"alpha\":np.array([0,0,0])}\n",
    "                P[i,:] = p\n",
    "                D[i,:] = d\n",
    "\n",
    "            elif symbol in b_sites:\n",
    "                zstar = zstars[\"B-site\"][symbol]\n",
    "                hedra_idx = np.argpartition(dists[i], 6)[:6]\n",
    "                headra_coords = oxygens[hedra_idx]\n",
    "                neis_x = headra_coords[headra_coords[:,0].argsort()[[0,-1]]]\n",
    "                neis_y = headra_coords[headra_coords[:,1].argsort()[[0,-1]]]\n",
    "                neis_z = headra_coords[headra_coords[:,2].argsort()[[0,-1]]]\n",
    "                alpha_x = calculate_angle(neis_x[0], cation_coords, neis_x[1])\n",
    "                alpha_y = calculate_angle(neis_y[0], cation_coords, neis_y[1])\n",
    "                alpha_z = calculate_angle(neis_z[0], cation_coords, neis_z[1])\n",
    "                alpha = np.array([alpha_x,alpha_y,alpha_z])\n",
    "                center_x = np.mean(neis_x, axis = 0)[0]\n",
    "                center_y = np.mean(neis_y, axis = 0)[1]\n",
    "                center_z = np.mean(neis_z, axis = 0)[2]\n",
    "                center = np.array([center_x, center_y, center_z])\n",
    "                d = cation_coords - center\n",
    "                p = calculate_polarization(zstar, d, V)\n",
    "                disp_pol_alpha[(\"B\", symbol, i)] = {\"p\":p, \"d\":d,\"hedra_idx\":hedra_idx, \"hedra\":headra_coords, \"alpha\":alpha}\n",
    "                P[i,:] = p\n",
    "                D[i,:] = d\n",
    "                alphas.append(alpha)\n",
    "            else:\n",
    "                print(f\"{cations_symbols[i]} not in A/B-sites\")\n",
    "\n",
    "        self.disp_pol_alpha = disp_pol_alpha\n",
    "        alphas = np.stack(alphas)\n",
    "        alphas = np.append(alphas, alphas.min(axis = 1).reshape(-1,1), axis = 1)\n",
    "        self.alphas = alphas\n",
    "        self.alphas_stat = np.array([np.min(alphas[:,-1]), np.mean(alphas[:,-1]), np.max(alphas[:,-1])])\n",
    "        P_tot = P.sum(axis = 0)\n",
    "        D_tot = D.sum(axis = 0)\n",
    "        self.P_tot = np.append(P_tot, np.sqrt(np.sum(P_tot**2)))\n",
    "        self.D_tot = np.append(D_tot, np.sqrt(np.sum(D_tot**2)))\n",
    "\n",
    "        self.P = np.concatenate([P, np.sum(P**2, axis = 1).reshape(-1, 1)], axis =1)\n",
    "        self.D = np.concatenate([D, np.sum(D**2, axis = 1).reshape(-1, 1)], axis =1)\n",
    "    \n",
    "    def get_df(self):\n",
    "        df = pd.DataFrame([[*key, *value[\"p\"], *value[\"d\"], *value[\"alpha\"]] for key, value in self.disp_pol_alpha.items()])\n",
    "        df.columns = [\"site\", \"cation\", \"cation_idx\", \"p_x\", \"p_y\", \"p_z\", \"d_x\", \"d_y\", \"d_z\", \"alpha_x\", \"alpha_y\", \"alpha_z\"]\n",
    "        df_grp = df.groupby([\"site\",\"cation\"]).describe()\n",
    "        df_p = df_grp.loc[:,([\"p_x\", \"p_y\", \"p_z\"],[\"mean\", \"std\", \"min\", \"max\"])]\n",
    "        df_d = df_grp.loc[:,([\"d_x\", \"d_y\", \"d_z\"],[\"mean\", \"std\", \"min\", \"max\"])]\n",
    "        df_alpha = df_grp.loc[:,([\"alpha_x\", \"alpha_y\", \"alpha_z\"],[\"mean\", \"std\", \"min\", \"max\"])]\n",
    "\n",
    "        self.df = df\n",
    "        self.df_p = df_p\n",
    "        self.df_d = df_d\n",
    "        self.df_alpha = df_alpha\n",
    "    \n",
    "    def print_log(self):\n",
    "        now = datetime.datetime.now()\n",
    "\n",
    "        table = [[\"\",\"p_x\", \"p_y\", \"p_z\", \"p_tot\", \"d_x\", \"d_y\", \"d_z\", \"d_tot\", \"alpha_max\", \"alpha_avg\", \"alpha_min\"],\n",
    "        [\"!\", *self.P_tot.round(7), *self.D_tot.round(7), *(180-self.alphas_stat).round(7)]]\n",
    "        with open(self.config[\"outname\"],\"w\") as log_file:\n",
    "            print(\"Output Data:\", self.config[\"name\"], now.strftime(\"%Y-%m-%d %H:%M:%S\"),file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"Summary Table\",file = log_file)\n",
    "            print(tabulate(table, tablefmt='psql'), file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"Polarization Statistics Table\",file = log_file)\n",
    "            print(tabulate(self.df_p.T, headers='keys', tablefmt='psql'), file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"Displacement Statistics Table\",file = log_file)\n",
    "            print(tabulate(self.df_d.T, headers='keys', tablefmt='psql'), file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"Alpha Statistics Table\",file = log_file)\n",
    "            print(tabulate(self.df_alpha.xs('B', level = 0).T, headers='keys', tablefmt='psql'), file = log_file)\n",
    "            \n",
    "            print(\"\",file = log_file)\n",
    "            print(\"\",file = log_file)\n",
    "            print(\"Verbose Summary\",file = log_file)\n",
    "\n",
    "            for x in self.disp_pol_alpha:\n",
    "                print(x, file = log_file)\n",
    "                pprint.pprint(self.disp_pol_alpha[x], log_file, sort_dicts = False, indent = 5)\n",
    "                print(\"\",file = log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_espresso_out(path, read_all):\n",
    "    with open(path, 'r') as f:\n",
    "        out = read_espresso_out(f,  index=slice(None))\n",
    "        objects = []\n",
    "        for item in out:\n",
    "            objects.append(item)\n",
    "        energies = [x.get_total_energy() for x in objects]\n",
    "        idx_min = np.argmin(energies)\n",
    "    if read_all:\n",
    "        return objects, objects[idx_min]\n",
    "    else:\n",
    "        return objects[idx_min], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"type\"] == \"vasp\":\n",
    "    obj = read_vasp(config[\"path\"])\n",
    "elif (config[\"type\"] == \"qe_in\"):\n",
    "    obj = read_espresso_in(config[\"path\"])\n",
    "elif (config[\"type\"] == \"qe_out\"):\n",
    "    obj = parse_espresso_out(config[\"path\"], config[\"read_all_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'get_positions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[43mStructure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     struct\u001b[38;5;241m.\u001b[39mget_pbc()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_pbc_vasp\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mStructure.__init__\u001b[0;34m(self, obj, config)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, config):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords_cartes \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_positions\u001b[49m()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords_direct \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_scaled_positions()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnat \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_global_number_of_atoms()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'get_positions'"
     ]
    }
   ],
   "source": [
    "if obj[1] == None:\n",
    "    struct = Structure(obj[0], config)\n",
    "    struct.get_pbc()\n",
    "    if config[\"save_pbc_vasp\"]:\n",
    "        write_vasp(config[\"name\"]+\"_pbc.vasp\", struct.obj_pbc, sort=True)\n",
    "    if config[\"type\"] != \"vasp\":\n",
    "        write_vasp(config[\"name\"]+\".vasp\", struct.obj, sort=True)\n",
    "    struct.get_disp_pol_alpha()\n",
    "    struct.get_df()\n",
    "    struct.print_log()\n",
    "else:\n",
    "    folder_name = config['name']\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Create folder if it doesn't exist\n",
    "    for i, item in enumerate(obj[0]):\n",
    "        struct = Structure(item, config)\n",
    "        config['outname'] = f\"{folder_name}/{config['name']}_{i+1}.out\"\n",
    "        struct.get_pbc()\n",
    "        if config[\"save_pbc_vasp\"]:\n",
    "            write_vasp(f\"{folder_name}/{config['name']}_pbc_{i+1}.vasp\", struct.obj_pbc, sort=True)\n",
    "        if config[\"type\"] != \"vasp\":\n",
    "            write_vasp(f\"{folder_name}/{config['name']}_{i+1}.vasp\", struct.obj, sort=True)\n",
    "        struct.get_disp_pol_alpha()\n",
    "        struct.get_df()\n",
    "        struct.print_log()\n",
    "    \n",
    "    struct = Structure(obj[1], config)\n",
    "    config['outname'] = f\"{folder_name}/{config['name']}_min.out\"\n",
    "    struct.get_pbc()\n",
    "    if config[\"save_pbc_vasp\"]:\n",
    "        write_vasp(f\"{folder_name}/{config['name']}_pbc_min.vasp\", struct.obj_pbc, sort=True)\n",
    "    if config[\"type\"] != \"vasp\":\n",
    "        write_vasp(f\"{folder_name}/{config['name']}_min.vasp\", struct.obj, sort=True)\n",
    "    struct.get_disp_pol_alpha()\n",
    "    struct.get_df()\n",
    "    struct.print_log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
